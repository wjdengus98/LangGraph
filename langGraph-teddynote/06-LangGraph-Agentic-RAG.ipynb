{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517af4d9",
   "metadata": {},
   "source": [
    "# Agentic RAG\n",
    "\n",
    "에이전트(Agent) 는 검색 도구를 사용할지 여부를 결정해야 할 때 유용합니다. 에이전트와 관련된 내용은 [Agent](https://wikidocs.net/233782) 페이지를 참고하세요.\n",
    "\n",
    "검색 에이전트를 구현하기 위해서는 `LLM`에 검색 도구에 대한 접근 권한을 부여하기만 하면 됩니다.\n",
    "\n",
    "이를 [LangGraph](https://langchain-ai.github.io/langgraph/)에 통합할 수 있습니다.\n",
    "\n",
    "![langgraph-agentic-rag](assets/langgraph-agentic-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532dc8f5",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4def9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1966105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Structures\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee354d2",
   "metadata": {},
   "source": [
    "## 기본 PDF 기반 Retrieval Chain 생성\n",
    "\n",
    "여기서는 PDF 문서를 기반으로 Retrieval Chain 을 생성합니다. 가장 단순한 구조의 Retrieval Chain 입니다.\n",
    "\n",
    "단, LangGraph 에서는 Retirever 와 Chain 을 따로 생성합니다. 그래야 각 노드별로 세부 처리를 할 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이전 튜토리얼에서 다룬 내용이므로, 자세한 설명은 생략합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d62a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever와 chain을 생성합니다.\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575f296",
   "metadata": {},
   "source": [
    "그 다음 `retriever_tool` 도구를 생성합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "`document_prompt` 는 검색된 문서를 표현하는 프롬프트입니다.\n",
    "\n",
    "**사용가능한 키** \n",
    "\n",
    "- `page_content`\n",
    "- `metadata` 의 키: (예시) `source`, `page`\n",
    "\n",
    "**사용예시**\n",
    "\n",
    "`\"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d6f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# PDF 문서를 기반으로 검색 도구 생성\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"Search and return information about SPRI AI Brief PDF file. It contains useful information on recent AI trends. The document is published on Dec 2023.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 생성된 검색 도구를 도구 리스트에 추가하여 에이전트에서 사용 가능하도록 설정\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09f9e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<document><context>SPRi AI Brief |\n",
      "2023-12월호\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "KEY Contents\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>12</page></metadata></document>\n",
      "\n",
      "<document><context>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>1</page></metadata></document>\n",
      "\n",
      "<document><context>£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>12</page></metadata></document>\n",
      "\n",
      "<document><context>어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>12</page></metadata></document>\n",
      "\n",
      "<document><context><구글 딥마인드의 범용 AI 분류 프레임워크>\n",
      "성능 특수 AI 예시 범용 AI 예시\n",
      "0단계: AI 아님 계산기 소프트웨어, 컴파일러 아마존 메커니컬 터크\n",
      "1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\n",
      "스마트 스피커(애플 시리, 아마존 알렉사, 구글\n",
      "2단계: 유능(숙련된 인간의 50% 이상) 미달성\n",
      "어시스턴트), IBM 왓슨\n",
      "3단계: 전문가(숙련된 인간의 90% 이상) 문법 교정기(그래머리), 생성 이미지 모델(달리2) 미달성</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>18</page></metadata></document>\n",
      "\n",
      "<document><context>제작을 포함\n",
      "n 알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를\n",
      "간소화하는 올인원 AI 모델 구축 플랫폼 ‘젠AI(GenAI)’도 공개\n",
      "∙ 이 플랫폼은 데이터 관리, 모델 배포와 평가, 신속한 엔지니어링을 위한 종합 도구 모음을 제공하여\n",
      "다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\n",
      "∙ 생성 AI 개발에 필요한 컴퓨팅과 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI),\n",
      "데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드 신제품도 발표</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>11</page></metadata></document>\n",
      "\n",
      "<document><context>처리를 지원\n",
      "∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>12</page></metadata></document>\n",
      "\n",
      "<document><context>온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\n",
      "처리를 지원</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>12</page></metadata></document>\n",
      "\n",
      "<document><context>▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································15</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>1</page></metadata></document>\n",
      "\n",
      "<document><context>£챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\n",
      "n 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와\n",
      "성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\n",
      "∙ 프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI\n",
      "달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\n",
      "n 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출</context><metadata><source>data/SPRI_AI_Brief_2023년12월호_F.pdf</source><page>18</page></metadata></document>\n"
     ]
    }
   ],
   "source": [
    "# print(retriever_tool.invoke(\"삼성전자가 개발한 생성형 AI의 이름은?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b169f21",
   "metadata": {},
   "source": [
    "## Agent 상태\n",
    "\n",
    "그래프를 정의하겠습니다.\n",
    "\n",
    "각 노드에 전달되는 `state` 객체입니다.\n",
    "\n",
    "상태는 `messages` 목록으로 구성됩니다.\n",
    "\n",
    "그래프의 각 노드는 이 목록에 내용을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55abb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 에이전트 상태를 정의하는 타입 딕셔너리, 메시지 시퀀스를 관리하고 추가 동작 정의\n",
    "class AgentState(TypedDict):\n",
    "    # add_messages reducer 함수를 사용하여 메시지 시퀀스를 관리 -> 리스트랑 동일\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f93141",
   "metadata": {},
   "source": [
    "## 노드와 엣지\n",
    "\n",
    "에이전트 기반 RAG 그래프는 다음과 같이 구성될 수 있습니다.\n",
    "\n",
    "* **상태**는 메시지들의 집합입니다\n",
    "* 각 **노드**는 상태를 업데이트(추가)합니다\n",
    "* **조건부 엣지**는 다음에 방문할 노드를 결정합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17b98e",
   "metadata": {},
   "source": [
    "간단한 채점기(Grader)를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d85a6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "#최신 모델이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d85971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_classic import hub\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "# 최신 모델이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# 데이터 모델 정의\n",
    "class grade(BaseModel):\n",
    "    \"\"\"A binary score for relevance checks\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Response 'yes' if the document is relevant to the question or 'no' if it is not.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    # LLM 모델 초기화\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "\n",
    "    # 구조화된 출력을 위한 LLM 설정\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # 프롬프트 템플릿 정의\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # llm + tool 바인딩 체인 생성\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 가장 마지막 메시지 추출\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 검색된 문서 추출\n",
    "    retrieved_docs = last_message.content\n",
    "\n",
    "    # 관련성 평가 실행\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": retrieved_docs})\n",
    "\n",
    "    # 관련성 여부 추출\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    # 관련성 여부에 따른 결정\n",
    "    if score == \"yes\":\n",
    "        print(\"==== [DECISION: DOCS RELEVANT] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"==== [DECISION: DOCS NOT RELEVANT] ====\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # LLM 모델 초기화\n",
    "    model = ChatOpenAI(temperature=0, streaming=True, model=MODEL_NAME)\n",
    "\n",
    "    # retriever tool 바인딩\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    # 에이전트 응답 생성\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 기존 리스트에 추가되므로 리스트 형태로 반환\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    print(\"==== [QUERY REWRITE] ====\")\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 질문 개선을 위한 프롬프트 구성\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # LLM 모델로 질문 개선\n",
    "    model = ChatOpenAI(temperature=0, model=MODEL_NAME, streaming=True)\n",
    "    # Query-Transform 체인 실행\n",
    "    response = model.invoke(msg)\n",
    "\n",
    "    # 재작성된 질문 반환\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    # 현재 상태에서 메시지 추출\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 원래 질문 추출\n",
    "    question = messages[0].content\n",
    "\n",
    "    # 가장 마지막 메시지 추출\n",
    "    docs = messages[-1].content\n",
    "\n",
    "    # RAG 프롬프트 템플릿 가져오기\n",
    "    prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "    # LLM 모델 초기화\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, streaming=True)\n",
    "\n",
    "    # RAG 체인 구성\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 답변 생성 실행\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481eb52",
   "metadata": {},
   "source": [
    "## 그래프\n",
    "\n",
    "* `call_model` 에이전트로 시작합니다\n",
    "* 에이전트가 함수를 호출할지 결정합니다\n",
    "* 함수 호출을 결정한 경우, 도구(retriever)를 호출하기 위한 `action`을 실행합니다\n",
    "* 도구의 출력값을 메시지(`state`)에 추가하여 에이전트를 호출합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42a95a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "functools.partial(<function _get_relevant_documents at 0x0000020AD1614040>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020AD330C650>, search_kwargs={'k': 10}), document_prompt=PromptTemplate(input_variables=['page', 'page_content', 'source'], input_types={}, partial_variables={}, template='<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>'), document_separator='\\n\\n', response_format='content') is not a module, class, method, or function.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 노드 정의\u001b[39;00m\n\u001b[32m      9\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m, agent)  \u001b[38;5;66;03m# 에이전트 노드\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m retrieve = \u001b[43mToolNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mretriever_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mretrieve\u001b[39m\u001b[33m\"\u001b[39m, retrieve)  \u001b[38;5;66;03m# 검색 노드\u001b[39;00m\n\u001b[32m     12\u001b[39m workflow.add_node(\u001b[33m\"\u001b[39m\u001b[33mrewrite\u001b[39m\u001b[33m\"\u001b[39m, rewrite)  \u001b[38;5;66;03m# 질문 재작성 노드\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\LangGraph(kr)\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:766\u001b[39m, in \u001b[36mToolNode.__init__\u001b[39m\u001b[34m(self, tools, name, tags, handle_tool_errors, messages_key, wrap_tool_call, awrap_tool_call)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28mself\u001b[39m._tools_by_name[tool_.name] = tool_\n\u001b[32m    765\u001b[39m \u001b[38;5;66;03m# Build injected args mapping once during initialization in a single pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28mself\u001b[39m._injected_args[tool_.name] = \u001b[43m_get_all_injected_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\LangGraph(kr)\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\tool_node.py:1801\u001b[39m, in \u001b[36m_get_all_injected_args\u001b[39m\u001b[34m(tool)\u001b[39m\n\u001b[32m   1798\u001b[39m schema_annotations = get_all_basemodel_annotations(full_schema)\n\u001b[32m   1800\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(tool, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(tool, \u001b[33m\"\u001b[39m\u001b[33mcoroutine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1801\u001b[39m func_annotations = \u001b[43mget_type_hints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_extras\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m   1803\u001b[39m \u001b[38;5;66;03m# Combine both annotation sources, preferring schema annotations\u001b[39;00m\n\u001b[32m   1804\u001b[39m \u001b[38;5;66;03m# In the future, we might want to add more restrictions here...\u001b[39;00m\n\u001b[32m   1805\u001b[39m all_annotations = {**func_annotations, **schema_annotations}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\typing.py:2245\u001b[39m, in \u001b[36mget_type_hints\u001b[39m\u001b[34m(obj, globalns, localns, include_extras)\u001b[39m\n\u001b[32m   2243\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m   2244\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m is not a module, class, method, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2246\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33mor function.\u001b[39m\u001b[33m'\u001b[39m.format(obj))\n\u001b[32m   2247\u001b[39m hints = \u001b[38;5;28mdict\u001b[39m(hints)\n\u001b[32m   2248\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m hints.items():\n",
      "\u001b[31mTypeError\u001b[39m: functools.partial(<function _get_relevant_documents at 0x0000020AD1614040>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020AD330C650>, search_kwargs={'k': 10}), document_prompt=PromptTemplate(input_variables=['page', 'page_content', 'source'], input_types={}, partial_variables={}, template='<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>'), document_separator='\\n\\n', response_format='content') is not a module, class, method, or function."
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# AgentState 기반 상태 그래프 워크플로우 초기화\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"agent\", agent)  # 에이전트 노드\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 검색 노드\n",
    "workflow.add_node(\"rewrite\", rewrite)  # 질문 재작성 노드\n",
    "workflow.add_node(\"generate\", generate)  # 관련 문서 확인 후 응답 생성 노드\n",
    "\n",
    "# 엣지 연결\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# 검색 여부 결정을 위한 조건부 엣지 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # 에이전트 결정 평가\n",
    "    tools_condition,\n",
    "    {\n",
    "        # 조건 출력을 그래프 노드에 매핑\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 액션 노드 실행 후 처리될 엣지 정의\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # 문서 품질 평가\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd907104",
   "metadata": {},
   "source": [
    "그래프를 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df716e28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_teddynote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualize_graph\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m visualize_graph(\u001b[43mgraph\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659e932",
   "metadata": {},
   "source": [
    "## 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import stream_graph, invoke_graph, random_uuid\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=10, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 사용자의 에이전트 메모리 유형에 대한 질문을 포함하는 입력 데이터 구조 정의\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"삼성전자가 개발한 생성형 AI 의 이름은?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(graph, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da64d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 스트리밍 출력\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577bd32",
   "metadata": {},
   "source": [
    "아래는 문서 검색이 **불필요한** 질문의 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1bc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 검색이 불가능한 질문 예시\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"대한민국의 수도는?\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac602bd",
   "metadata": {},
   "source": [
    "아래는 임의로 **문서 검색이 불가능한** 질문 예시입니다.\n",
    "\n",
    "따라서, 문서를 지속적으로 검색하는 과정에서 `GraphRecursionError` 가 발생하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ac07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "# 문서 검색이 불가능한 질문 예시\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"테디노트의 랭체인 튜토리얼에 대해서 알려줘\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    # 그래프 실행\n",
    "    stream_graph(graph, inputs, config, [\"agent\", \"rewrite\", \"generate\"])\n",
    "except GraphRecursionError as recursion_error:\n",
    "    print(f\"GraphRecursionError: {recursion_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c093f5c",
   "metadata": {},
   "source": [
    "다음 튜토리얼에서는 이를 해결하는 방법을 다룹니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
